# encoding:utf-8
"""
LLM Bot æ¨¡å—
å¯¹æ¥ç§æœ‰åŒ–LLMç½‘å…³ï¼ˆOpenAIæ ‡å‡†æ¥å£ï¼‰
"""

import time
from typing import Dict, List, Optional

import openai

from common.logger import logger
from common.session_manager import get_session_manager
from config import get_config


class LLMBot:
    """
    LLMæœºå™¨äºº
    æ”¯æŒOpenAIæ ‡å‡†æ¥å£çš„ç§æœ‰åŒ–LLMç½‘å…³
    """
    
    def __init__(self):
        self.config = get_config()
        self._setup_openai()
        logger.info("[LLMBot] Initialized")
    
    def _setup_openai(self):
        """é…ç½®OpenAIå®¢æˆ·ç«¯"""
        # è®¾ç½®API Key
        openai.api_key = self.config.get("llm_api_key", "")
        
        # è®¾ç½®API Baseï¼ˆç§æœ‰åŒ–ç½‘å…³åœ°å€ï¼‰
        api_base = self.config.get("llm_api_base", "")
        if api_base:
            openai.api_base = api_base
            logger.info(f"[LLMBot] Using custom API base: {api_base}")
    
    def chat(self, query: str, session_id: str, context: Optional[Dict] = None) -> str:
        """
        å¯¹è¯
        
        :param query: ç”¨æˆ·è¾“å…¥
        :param session_id: ä¼šè¯ID
        :param context: é¢å¤–ä¸Šä¸‹æ–‡
        :return: æœºå™¨äººå›å¤
        """
        try:
            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            reply = self._handle_command(query, session_id)
            if reply:
                return reply
            
            # è·å–ä¼šè¯å¹¶æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            session_manager = get_session_manager()
            session = session_manager.get_session(session_id)
            
            # å¦‚æœæ˜¯æ–°ä¼šè¯ï¼Œæ·»åŠ ç³»ç»Ÿæç¤º
            if not session.messages:
                character_desc = self.config.get("character_desc", "")
                if character_desc:
                    session.add_message("system", character_desc)
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            session.add_message("user", query)
            
            # è°ƒç”¨LLM
            response = self._call_llm(session.get_messages())
            
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°ä¼šè¯
            session.add_message("assistant", response)
            
            return response
            
        except Exception as e:
            logger.error(f"[LLMBot] Chat error: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼š{str(e)}"
    
    def _handle_command(self, query: str, session_id: str) -> Optional[str]:
        """
        å¤„ç†å†…ç½®å‘½ä»¤
        
        :param query: ç”¨æˆ·è¾“å…¥
        :param session_id: ä¼šè¯ID
        :return: å¦‚æœæ˜¯å‘½ä»¤è¿”å›å›å¤ï¼Œå¦åˆ™è¿”å›None
        """
        query = query.strip()
        
        # æ¸…é™¤è®°å¿†å‘½ä»¤
        clear_commands = ["#æ¸…é™¤è®°å¿†", "#æ¸…ç©º", "#reset", "/reset", "/clear"]
        if query in clear_commands:
            session_manager = get_session_manager()
            session_manager.clear_session(session_id)
            return "ğŸ§¹ ä¼šè¯è®°å¿†å·²æ¸…é™¤ï¼Œè®©æˆ‘ä»¬å¼€å§‹æ–°çš„å¯¹è¯å§ï¼"
        
        # å¸®åŠ©å‘½ä»¤
        help_commands = ["#å¸®åŠ©", "#help", "/help"]
        if query in help_commands:
            return self._get_help_text()
        
        return None
    
    def _get_help_text(self) -> str:
        """è·å–å¸®åŠ©æ–‡æœ¬"""
        return """ğŸ¤– **WPSæ™ºèƒ½åŠ©æ‰‹ä½¿ç”¨æŒ‡å—**

**åŸºæœ¬åŠŸèƒ½ï¼š**
â€¢ ç›´æ¥å‘é€æ¶ˆæ¯ä¸æˆ‘å¯¹è¯
â€¢ æˆ‘å¯ä»¥å›ç­”é—®é¢˜ã€ç”Ÿæˆå†…å®¹ã€è¾…åŠ©åŠå…¬

**å¸¸ç”¨å‘½ä»¤ï¼š**
â€¢ `#å¸®åŠ©` / `#help` - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
â€¢ `#æ¸…é™¤è®°å¿†` / `#reset` - æ¸…ç©ºå½“å‰ä¼šè¯è®°å¿†

**æç¤ºï¼š**
â€¢ åœ¨ç¾¤èŠä¸­@æˆ‘å³å¯è§¦å‘å¯¹è¯
â€¢ ç§èŠå¯ç›´æ¥å‘é€æ¶ˆæ¯
â€¢ æˆ‘ä¼šè®°ä½å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ–¹ä¾¿è¿ç»­äº¤æµ"""
    
    def _call_llm(self, messages: List[Dict]) -> str:
        """
        è°ƒç”¨LLM API
        
        :param messages: æ¶ˆæ¯åˆ—è¡¨
        :return: LLMå›å¤
        """
        try:
            model = self.config.get("llm_model", "gpt-3.5-turbo")
            temperature = self.config.get("temperature", 0.7)
            max_tokens = self.config.get("max_tokens", 2048)
            request_timeout = self.config.get("request_timeout", 120)
            
            logger.debug(f"[LLMBot] Calling LLM with {len(messages)} messages")
            
            response = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=self.config.get("top_p", 1.0),
                frequency_penalty=self.config.get("frequency_penalty", 0.0),
                presence_penalty=self.config.get("presence_penalty", 0.0),
                request_timeout=request_timeout
            )
            
            content = response.choices[0].message.content
            usage = response.get("usage", {})
            
            logger.info(
                f"[LLMBot] LLM response received, "
                f"tokens: prompt={usage.get('prompt_tokens', 0)}, "
                f"completion={usage.get('completion_tokens', 0)}"
            )
            
            return content.strip()
            
        except openai.error.RateLimitError as e:
            logger.error(f"[LLMBot] Rate limit error: {e}")
            return "âš ï¸ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
        
        except openai.error.Timeout as e:
            logger.error(f"[LLMBot] Timeout error: {e}")
            return "â±ï¸ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
        
        except openai.error.APIError as e:
            logger.error(f"[LLMBot] API error: {e}")
            return f"ğŸ”Œ APIé”™è¯¯ï¼š{str(e)}"
        
        except Exception as e:
            logger.error(f"[LLMBot] LLM call failed: {e}")
            raise
    
    def _call_llm_with_retry(self, messages: List[Dict], retry_count: int = 0) -> str:
        """
        å¸¦é‡è¯•çš„LLMè°ƒç”¨
        
        :param messages: æ¶ˆæ¯åˆ—è¡¨
        :param retry_count: å½“å‰é‡è¯•æ¬¡æ•°
        :return: LLMå›å¤
        """
        max_retries = 2
        
        try:
            return self._call_llm(messages)
        except Exception as e:
            if retry_count < max_retries:
                wait_time = 3 * (retry_count + 1)
                logger.warning(f"[LLMBot] Retry {retry_count + 1} after {wait_time}s")
                time.sleep(wait_time)
                return self._call_llm_with_retry(messages, retry_count + 1)
            else:
                raise


# å…¨å±€Botå®ä¾‹
_bot: Optional[LLMBot] = None


def get_bot() -> LLMBot:
    """è·å–å…¨å±€Botå®ä¾‹"""
    global _bot
    if _bot is None:
        _bot = LLMBot()
    return _bot
